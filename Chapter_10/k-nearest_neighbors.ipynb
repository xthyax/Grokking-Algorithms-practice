{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this chapter\n",
    "---\n",
    "* You learn to build a classification system using the k-nearest neighbors algorithm.\n",
    "* You learn about feature extraction.\n",
    "* You learn about regression: predicting a number, like the value of a stock tomorrow, or how much user will enjoy a movie.\n",
    "* You learn about the use cases and limitations of k-nearest neightbors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "---\n",
    "10.1 In the Netflix...How would you take their different rating strategies into account?\n",
    "> *Answer*: Can convert the 5 star rating into different scaler: Like(5s & 4s) - Neutral(3s) and Dislike(below 2s)\n",
    ">\n",
    "> **Result**: You could use something called *normalization*. You look at the average rating for each person and use it to scale their ratings.\n",
    "\n",
    "10.2 Suppose Netflix...How would change the recommendation system...?\n",
    "> *Answer*: The easiest way is to weights the influencers rating\n",
    ">\n",
    "> **Result**: You could give more weight to the ratings of the influencers when using KNN. Suppose you have three neighbors: A, B, and C (as influencer). They rated a movie a 3, a 4, and a 5, respectively. Instead of just taking the average of their ratings (3 + 4 + 5 / 3 = 4 stars), you could give C's rating more weight: 3 + 4 + 5 * 3 / 5 = 4.4 stars.\n",
    "\n",
    "10.3 Netflix has millions of users...Is this too low? Too high?\n",
    "> *Answer*: Too low\n",
    ">\n",
    "> **Result**: It's too low. If you look at fewer neighbors, there's a bigger chance that the results will be skewed. A good rule of thumb is, if you have *N* users, you should look at sqrt(*N*) neighbors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "---\n",
    "* KNN is used for classification and regression and involves looking at the k-nearest neighbors.\n",
    "* Classification = categorization into a group.\n",
    "* Regression = predicting a response (like a number).\n",
    "* Feature extraction means converting an item (like a fruit or a user) into a list of number that can be compared\n",
    "* Picking good features is an important part of a successful KNN algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
